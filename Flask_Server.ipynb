{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e6a0c7-dcfb-41db-b214-a151acbf8f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8890\n",
      " * Running on http://172.17.0.2:8890\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "from ml4h.models.model_factory import get_custom_objects\n",
    "from ml4h.tensormap.ukb.survival import mgb_afib_wrt_instance2\n",
    "from ml4h.tensormap.ukb.demographics import age_2_wide, af_dummy, sex_dummy3\n",
    "from flask_cors import CORS \n",
    "\n",
    "# Create a Flask application instance\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable Cross-Origin Resource Sharing\n",
    "\n",
    "# Base path for storing uploaded files\n",
    "BASE_PATH = os.getenv('BASE_PATH', '/home/pravinpawar381997')\n",
    "\n",
    "# Name of the model file (without the .h5 extension)\n",
    "MODEL_NAME = os.getenv('MODEL_NAME', 'ecg_5000_survival_curve_af_quadruple_task_mgh_v2021_05_21') \n",
    "\n",
    "# Complete path for the model file\n",
    "MODEL_PATH = os.path.join(BASE_PATH, f'{MODEL_NAME}.h5')\n",
    "\n",
    "# Mapping of ECG lead names to their respective indices in the tensor\n",
    "ECG_REST_LEADS = {\n",
    "    'strip_I': 0, 'strip_II': 1, 'strip_III': 2, 'strip_V1': 3,\n",
    "    'strip_V2': 4, 'strip_V3': 5, 'strip_V4': 6, 'strip_V5': 7,\n",
    "    'strip_V6': 8, 'strip_aVF': 9, 'strip_aVL': 10, 'strip_aVR': 11,\n",
    "}\n",
    "\n",
    "# Shape of the ECG data tensor (5000 time points, 12 leads)\n",
    "ECG_SHAPE = (5000, 12)\n",
    "\n",
    "# Path in the HDF5 file to access ECG data\n",
    "ECG_HD5_PATH = 'ukb_ecg_rest'\n",
    "\n",
    "def ecg_as_tensor(ecg_file):\n",
    "    \"\"\"Convert the uploaded HDF5 ECG file to a normalized tensor.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(ecg_file, 'r') as hd5:\n",
    "            tensor = np.zeros(ECG_SHAPE, dtype=np.float32)  # Initialize tensor\n",
    "            # Populate tensor with ECG lead data from the HDF5 file\n",
    "            for lead in ECG_REST_LEADS:\n",
    "                data = np.array(hd5[f'{ECG_HD5_PATH}/{lead}/instance_0'])\n",
    "                tensor[:, ECG_REST_LEADS[lead]] = data\n",
    "            # Normalize the tensor data\n",
    "            tensor -= np.mean(tensor)  # Subtract mean\n",
    "            tensor /= np.std(tensor) + 1e-6  # Divide by standard deviation, add small constant to avoid division by zero\n",
    "        return tensor\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Missing data in HDF5 file: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error processing HDF5 file: {str(e)}\")\n",
    "\n",
    "# Create a mapping of output tensor maps and load custom objects for the model\n",
    "output_tensormaps = {tm.output_name(): tm for tm in [mgb_afib_wrt_instance2, age_2_wide, af_dummy, sex_dummy3]}\n",
    "custom_dict = get_custom_objects([mgb_afib_wrt_instance2, age_2_wide, af_dummy, sex_dummy3])\n",
    "\n",
    "# Load the pre-trained model for predictions\n",
    "try:\n",
    "    model = load_model(MODEL_PATH, custom_objects=custom_dict)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error loading the model: {str(e)}\")\n",
    "\n",
    "# Define a simple GET endpoint that returns a greeting message\n",
    "@app.route('/home', methods=['GET'])\n",
    "def hello():\n",
    "    return jsonify({\"message\": \"Hello, World!\"})\n",
    "\n",
    "# Define a POST endpoint for making predictions with uploaded ECG data\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"Handle the prediction request and return the results.\"\"\"\n",
    "    # Check if a file is part of the request\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part in the request\"}), 400\n",
    "    \n",
    "    file = request.files['file']\n",
    "    \n",
    "    # Check if a file was actually selected\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"}), 400\n",
    "    \n",
    "    # Check if the uploaded file is an HDF5 file\n",
    "    if not file.filename.endswith('.h5'):\n",
    "        return jsonify({\"error\": \"Uploaded file is not an HDF5 file. Please upload a .h5 file.\"}), 400\n",
    "    \n",
    "    # Save the uploaded HDF5 file to a temporary location\n",
    "    file_path = os.path.join(BASE_PATH, file.filename)\n",
    "    try:\n",
    "        file.save(file_path)  # Save the file\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Failed to save file: {str(e)}\"}), 500\n",
    "    \n",
    "    # Convert the uploaded HDF5 file to a tensor\n",
    "    try:\n",
    "        tensor = ecg_as_tensor(file_path)\n",
    "    except ValueError as ve:\n",
    "        return jsonify({\"error\": str(ve)}), 400\n",
    "    except RuntimeError as re:\n",
    "        return jsonify({\"error\": str(re)}), 500\n",
    "\n",
    "    # Make predictions using the model\n",
    "    try:\n",
    "        predictions = model.predict(np.expand_dims(tensor, axis=0))  # Expand dimensions for batch processing\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Prediction error: {str(e)}\"}), 500\n",
    "\n",
    "    results = []  # Store the results of predictions\n",
    "    for name, pred in zip(model.output_names, predictions):\n",
    "        otm = output_tensormaps[name]  # Get the corresponding output tensor map\n",
    "        if otm.is_survival_curve():  # Check if the output is a survival curve\n",
    "            intervals = otm.shape[-1] // 2  # Number of intervals for survival prediction\n",
    "            days_per_bin = 1 + otm.days_window // intervals  # Calculate days per bin\n",
    "            predicted_survivals = np.cumprod(pred[:, :intervals], axis=1)  # Calculate cumulative product for survival\n",
    "            results.append(f'AF Risk {otm} prediction is: {str(1 - predicted_survivals[0, -1])}')  # Append result\n",
    "        else:\n",
    "            results.append(f'{otm} prediction is {pred}')  # Append other predictions\n",
    "\n",
    "    # Return the predictions as a JSON response\n",
    "    return jsonify({\"response\": results}), 201\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the app on port 8889, accessible from any host\n",
    "    app.run(host='0.0.0.0', port=os.getenv('PORT', 8890))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8f7df-549e-4dcf-9902-a9517f1929b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
